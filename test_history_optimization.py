#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å†å²è®°å½•ä¼˜åŒ–åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crazy_functions.undefine_paper_detail_reading import BatchPaperDetailAnalyzer, DeepReadQuestion

def test_token_estimation():
    """æµ‹è¯•tokenä¼°ç®—åŠŸèƒ½"""
    print("æµ‹è¯•tokenä¼°ç®—åŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    analyzer = BatchPaperDetailAnalyzer(
        llm_kwargs={'llm_model': 'gpt-3.5-turbo'},
        plugin_kwargs={},
        chatbot=[],
        history=[],
        system_prompt="æµ‹è¯•"
    )
    
    # æµ‹è¯•tokenä¼°ç®—
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯tokenä¼°ç®—åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
    estimated_tokens = analyzer._estimate_tokens(test_text)
    print(f"æ–‡æœ¬: {test_text}")
    print(f"ä¼°ç®—tokens: {estimated_tokens}")
    
    # æµ‹è¯•tokenç»Ÿè®¡æ›´æ–°
    analyzer._update_token_stats(test_text, "è¿™æ˜¯å›å¤æ–‡æœ¬")
    print(f"Tokenç»Ÿè®¡: {analyzer._token_usage_stats}")
    
    print("âœ… Tokenä¼°ç®—åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_progressive_context():
    """æµ‹è¯•é€’è¿›å¼ä¸Šä¸‹æ–‡æ„å»º"""
    print("\næµ‹è¯•é€’è¿›å¼ä¸Šä¸‹æ–‡æ„å»º...")
    
    analyzer = BatchPaperDetailAnalyzer(
        llm_kwargs={'llm_model': 'gpt-3.5-turbo'},
        plugin_kwargs={},
        chatbot=[],
        history=[],
        system_prompt="æµ‹è¯•"
    )
    
    # æ¨¡æ‹Ÿä¸€äº›åˆ†æç»“æœ
    analyzer.results = {
        "problem_domain_and_motivation": "è¿™æ˜¯ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ çš„é—®é¢˜åŸŸåˆ†æç»“æœ",
        "theoretical_framework_and_contributions": "è¿™æ˜¯ç†è®ºæ¡†æ¶åˆ†æç»“æœ"
    }
    
    # æµ‹è¯•é—®é¢˜
    test_question = DeepReadQuestion(
        id="method_design_and_technical_details",
        question="è¯·åˆ†ææŠ€æœ¯å®ç°ç»†èŠ‚",
        importance=5,
        description="æ–¹æ³•è®¾è®¡ä¸æŠ€æœ¯ç»†èŠ‚",
        domain="both"
    )
    
    # æ„å»ºé€’è¿›å¼ä¸Šä¸‹æ–‡
    context_parts = analyzer._build_progressive_context(test_question)
    print(f"æ„å»ºçš„ä¸Šä¸‹æ–‡éƒ¨åˆ†æ•°é‡: {len(context_parts)}")
    for i, part in enumerate(context_parts):
        print(f"ä¸Šä¸‹æ–‡éƒ¨åˆ† {i+1}: {part[:100]}...")
    
    print("âœ… é€’è¿›å¼ä¸Šä¸‹æ–‡æ„å»ºæµ‹è¯•é€šè¿‡")

def test_related_analysis():
    """æµ‹è¯•é—®é¢˜ç›¸å…³æ€§åˆ¤æ–­"""
    print("\næµ‹è¯•é—®é¢˜ç›¸å…³æ€§åˆ¤æ–­...")
    
    analyzer = BatchPaperDetailAnalyzer(
        llm_kwargs={'llm_model': 'gpt-3.5-turbo'},
        plugin_kwargs={},
        chatbot=[],
        history=[],
        system_prompt="æµ‹è¯•"
    )
    
    # æµ‹è¯•ç›¸å…³æ€§é—®é¢˜
    is_related = analyzer._is_related_analysis(
        "problem_domain_and_motivation",
        "theoretical_framework_and_contributions"
    )
    print(f"é—®é¢˜åŸŸåˆ†æ -> ç†è®ºæ¡†æ¶åˆ†æ: ç›¸å…³ = {is_related}")
    
    is_related = analyzer._is_related_analysis(
        "problem_domain_and_motivation",
        "flowcharts_and_architecture"
    )
    print(f"é—®é¢˜åŸŸåˆ†æ -> æµç¨‹å›¾åˆ†æ: ç›¸å…³ = {is_related}")
    
    print("âœ… é—®é¢˜ç›¸å…³æ€§åˆ¤æ–­æµ‹è¯•é€šè¿‡")

def test_token_usage_summary():
    """æµ‹è¯•tokenä½¿ç”¨æ‘˜è¦"""
    print("\næµ‹è¯•tokenä½¿ç”¨æ‘˜è¦...")
    
    analyzer = BatchPaperDetailAnalyzer(
        llm_kwargs={'llm_model': 'gpt-3.5-turbo'},
        plugin_kwargs={},
        chatbot=[],
        history=[],
        system_prompt="æµ‹è¯•"
    )
    
    # æ¨¡æ‹Ÿä¸€äº›äº¤äº’
    analyzer._update_token_stats("è¾“å…¥æ–‡æœ¬1", "è¾“å‡ºæ–‡æœ¬1")
    analyzer._update_token_stats("è¾“å…¥æ–‡æœ¬2", "è¾“å‡ºæ–‡æœ¬2")
    
    # è·å–æ‘˜è¦
    summary = analyzer._get_token_usage_summary()
    print("Tokenä½¿ç”¨æ‘˜è¦:")
    print(summary)
    
    print("âœ… Tokenä½¿ç”¨æ‘˜è¦æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•å†å²è®°å½•ä¼˜åŒ–åŠŸèƒ½...\n")
    
    try:
        test_token_estimation()
        test_progressive_context()
        test_related_analysis()
        test_token_usage_summary()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å†å²è®°å½•ä¼˜åŒ–åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

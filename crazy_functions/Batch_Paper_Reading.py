import os
import time
import glob
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass
from typing import Dict, List, Generator, Tuple
from crazy_functions.crazy_utils import request_gpt_model_in_new_thread_with_ui_alive
from toolbox import update_ui, promote_file_to_downloadzone, write_history_to_file, CatchException, report_exception
from shared_utils.fastapi_server import validate_path_safety
from crazy_functions.paper_fns.paper_download import extract_paper_id, extract_paper_ids, get_arxiv_paper, format_arxiv_id

# æ–°å¢ï¼šè¯·æ±‚é™æµå’Œé‡è¯•æ§åˆ¶
import queue
import random
from threading import Semaphore 


@dataclass
class PaperQuestion:
    """è®ºæ–‡åˆ†æé—®é¢˜ç±»"""
    id: str  # é—®é¢˜ID
    question: str  # é—®é¢˜å†…å®¹
    importance: int  # é‡è¦æ€§ (1-5ï¼Œ5æœ€é«˜)
    description: str  # é—®é¢˜æè¿°


class BatchPaperAnalyzer:
    """æ‰¹é‡è®ºæ–‡å¿«é€Ÿåˆ†æå™¨"""

    def __init__(self, llm_kwargs: Dict, plugin_kwargs: Dict, chatbot: List, history: List, system_prompt: str):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.llm_kwargs = llm_kwargs
        self.plugin_kwargs = plugin_kwargs
        self.chatbot = chatbot
        self.history = history
        self.system_prompt = system_prompt
        self.paper_content = ""
        self.results = {}
        self.paper_file_path = None
        self.progress_lock = threading.Lock()  # è¿›åº¦é”
        self.current_progress = 0
        self.total_papers = 0
        
        # æ–°å¢ï¼šè¯¦ç»†è¿›åº¦è·Ÿè¸ª
        self.current_paper_name = ""
        self.current_question_index = 0
        self.total_questions = 0
        self.processing_stage = ""  # å½“å‰å¤„ç†é˜¶æ®µï¼šloading, analyzing, summarizing, saving
        
        # æ–°å¢ï¼šè¯·æ±‚é™æµæ§åˆ¶
        self.request_semaphore = Semaphore(2)  # æœ€å¤šåŒæ—¶2ä¸ªAPIè¯·æ±‚
        self.retry_delay = 5  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

        # å®šä¹‰è®ºæ–‡åˆ†æé—®é¢˜åº“ï¼ˆä¸Paper_Readingä¿æŒä¸€è‡´ï¼‰
        self.questions = [
            PaperQuestion(
                id="research_and_methods",
                question="è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦ç ”ç©¶é—®é¢˜ã€ç›®æ ‡å’Œæ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿè¯·åˆ†æï¼š1)è®ºæ–‡çš„æ ¸å¿ƒç ”ç©¶é—®é¢˜å’Œç ”ç©¶åŠ¨æœºï¼›2)è®ºæ–‡æå‡ºçš„å…³é”®æ–¹æ³•ã€æ¨¡å‹æˆ–ç†è®ºæ¡†æ¶ï¼›3)è¿™äº›æ–¹æ³•å¦‚ä½•è§£å†³ç ”ç©¶é—®é¢˜ã€‚",
                importance=5,
                description="ç ”ç©¶é—®é¢˜ä¸æ–¹æ³•"
            ),
            PaperQuestion(
                id="findings_and_innovation",
                question="è®ºæ–‡çš„ä¸»è¦å‘ç°ã€ç»“è®ºåŠåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿè¯·åˆ†æï¼š1)è®ºæ–‡çš„æ ¸å¿ƒç»“æœä¸ä¸»è¦å‘ç°ï¼›2)ä½œè€…å¾—å‡ºçš„å…³é”®ç»“è®ºï¼›3)ç ”ç©¶çš„åˆ›æ–°ç‚¹ä¸å¯¹é¢†åŸŸçš„è´¡çŒ®ï¼›4)ä¸å·²æœ‰å·¥ä½œçš„åŒºåˆ«ã€‚",
                importance=4,
                description="ç ”ç©¶å‘ç°ä¸åˆ›æ–°"
            ),
            PaperQuestion(
                id="methodology_and_data",
                question="è®ºæ–‡ä½¿ç”¨äº†ä»€ä¹ˆç ”ç©¶æ–¹æ³•å’Œæ•°æ®ï¼Ÿè¯·è¯¦ç»†åˆ†æï¼š1)ç ”ç©¶è®¾è®¡ä¸å®éªŒè®¾ç½®ï¼›2)æ•°æ®æ”¶é›†æ–¹æ³•ä¸æ•°æ®é›†ç‰¹ç‚¹ï¼›3)åˆ†ææŠ€æœ¯ä¸è¯„ä¼°æ–¹æ³•ï¼›4)æ–¹æ³•å­¦ä¸Šçš„åˆç†æ€§ã€‚",
                importance=3,
                description="ç ”ç©¶æ–¹æ³•ä¸æ•°æ®"
            ),
            PaperQuestion(
                id="limitations_and_impact",
                question="è®ºæ–‡çš„å±€é™æ€§ã€æœªæ¥æ–¹å‘åŠæ½œåœ¨å½±å“æ˜¯ä»€ä¹ˆï¼Ÿè¯·åˆ†æï¼š1)ç ”ç©¶çš„ä¸è¶³ä¸é™åˆ¶å› ç´ ï¼›2)ä½œè€…æå‡ºçš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼›3)è¯¥ç ”ç©¶å¯¹å­¦æœ¯ç•Œå’Œè¡Œä¸šå¯èƒ½äº§ç”Ÿçš„å½±å“ï¼›4)ç ”ç©¶ç»“æœçš„é€‚ç”¨èŒƒå›´ä¸æ¨å¹¿ä»·å€¼ã€‚",
                importance=2,
                description="å±€é™æ€§ä¸å½±å“"
            ),
        ]

        # æŒ‰é‡è¦æ€§æ’åº
        self.questions.sort(key=lambda q: q.importance, reverse=True)
        self.total_questions = len(self.questions)

    def update_detailed_progress(self, paper_name: str, stage: str, question_index: int = -1, status: str = ""):
        """æ›´æ–°è¯¦ç»†å¤„ç†è¿›åº¦"""
        with self.progress_lock:
            self.current_paper_name = paper_name
            self.processing_stage = stage
            if question_index >= 0:
                self.current_question_index = question_index
            
            # æ„å»ºè¿›åº¦æ¶ˆæ¯
            progress_msg = f"ğŸ“Š æ‰¹é‡è®ºæ–‡åˆ†æè¿›åº¦\n\n"
            progress_msg += f"ğŸ“„ å½“å‰è®ºæ–‡: {paper_name}\n"
            progress_msg += f"ğŸ”„ å¤„ç†é˜¶æ®µ: {stage}\n"
            
            if stage == "analyzing" and question_index >= 0:
                question = self.questions[question_index]
                progress_msg += f"â“ å½“å‰é—®é¢˜ ({question_index + 1}/{self.total_questions}): {question.description}\n"
                progress_msg += f"ğŸ“ˆ é—®é¢˜è¿›åº¦: {question_index + 1}/{self.total_questions}\n"
            
            if status:
                progress_msg += f"ğŸ“‹ çŠ¶æ€: {status}\n"
            
            # æ›´æ–°è¿›åº¦æ˜¾ç¤º
            if len(self.chatbot) > 0 and "æ‰¹é‡è®ºæ–‡åˆ†æè¿›åº¦" in self.chatbot[-1][0]:
                self.chatbot[-1] = ["æ‰¹é‡è®ºæ–‡åˆ†æè¿›åº¦", progress_msg]
            else:
                self.chatbot.append(["æ‰¹é‡è®ºæ–‡åˆ†æè¿›åº¦", progress_msg])

    def update_paper_progress(self, paper_name: str, status: str):
        """æ›´æ–°è®ºæ–‡å¤„ç†è¿›åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºæœ€ç»ˆçŠ¶æ€ï¼‰"""
        with self.progress_lock:
            self.current_progress += 1
            progress_percent = (self.current_progress / self.total_papers) * 100
            progress_msg = f"ğŸ“Š è®ºæ–‡å¤„ç†è¿›åº¦: {self.current_progress}/{self.total_papers} ({progress_percent:.1f}%) - {paper_name}: {status}"
            
            # æ›´æ–°è¿›åº¦æ˜¾ç¤º
            if len(self.chatbot) > 0 and "è®ºæ–‡å¤„ç†è¿›åº¦" in self.chatbot[-1][0]:
                self.chatbot[-1] = ["è®ºæ–‡å¤„ç†è¿›åº¦", progress_msg]
            else:
                self.chatbot.append(["è®ºæ–‡å¤„ç†è¿›åº¦", progress_msg])

    def _load_paper(self, paper_path: str) -> bool:
        """åŠ è½½è®ºæ–‡å†…å®¹ - éç”Ÿæˆå™¨ç‰ˆæœ¬ï¼Œç”¨äºå¤šçº¿ç¨‹"""
        from crazy_functions.doc_fns.text_content_loader import TextContentLoader
        
        # ä¿å­˜è®ºæ–‡æ–‡ä»¶è·¯å¾„
        self.paper_file_path = paper_path
        paper_name = os.path.basename(paper_path)
        
        # æ›´æ–°è¿›åº¦
        self.update_detailed_progress(paper_name, "loading", status="æ­£åœ¨åŠ è½½è®ºæ–‡å†…å®¹...")

        try:
            # ä½¿ç”¨TextContentLoaderè¯»å–æ–‡ä»¶
            loader = TextContentLoader(self.chatbot, self.history)
            
            # æ‰§è¡Œæ–‡ä»¶åŠ è½½
            for _ in loader.execute_single_file(paper_path):
                pass  # å¿½ç•¥ç”Ÿæˆå™¨è¾“å‡º
            
            # è·å–åŠ è½½çš„å†…å®¹
            if len(self.history) >= 2 and self.history[-2]:
                self.paper_content = self.history[-2]
                self.update_detailed_progress(paper_name, "loading", status="âœ… è®ºæ–‡åŠ è½½å®Œæˆ")
                return True
            else:
                self.update_detailed_progress(paper_name, "loading", status="âŒ è®ºæ–‡åŠ è½½å¤±è´¥")
                return False
        except Exception as e:
            self.update_detailed_progress(paper_name, "loading", status=f"âŒ åŠ è½½é”™è¯¯: {str(e)}")
            return False

    def _analyze_question(self, question: PaperQuestion, question_index: int) -> bool:
        """åˆ†æå•ä¸ªé—®é¢˜ - éç”Ÿæˆå™¨ç‰ˆæœ¬ï¼Œç”¨äºå¤šçº¿ç¨‹"""
        paper_name = os.path.basename(self.paper_file_path) if self.paper_file_path else "æœªçŸ¥è®ºæ–‡"
        
        # æ›´æ–°è¿›åº¦
        self.update_detailed_progress(paper_name, "analyzing", question_index, f"æ­£åœ¨åˆ†æ: {question.description}")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘è¯·æ±‚
        with self.request_semaphore:
            for retry_count in range(self.max_retries):
                try:
                    # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚å†²çª
                    if retry_count > 0:
                        delay = self.retry_delay + random.uniform(1, 3)
                        time.sleep(delay)
                        self.update_detailed_progress(paper_name, "analyzing", question_index, 
                                                   f"é‡è¯•åˆ†æ ({retry_count + 1}/{self.max_retries}): {question.description}")
                    
                    # æ£€æŸ¥è®ºæ–‡å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
                    content_length = len(self.paper_content)
                    if content_length > 80000:  # è®¾ç½®å®‰å…¨é˜ˆå€¼
                        # æˆªå–è®ºæ–‡å†…å®¹çš„æ ¸å¿ƒéƒ¨åˆ†
                        truncated_content = self.paper_content[:80000] + "\n\n[å†…å®¹å·²æˆªå–ï¼Œä¿ç•™æ ¸å¿ƒéƒ¨åˆ†]"
                        self.update_detailed_progress(paper_name, "analyzing", question_index, 
                                                   f"è®ºæ–‡å†…å®¹è¿‡é•¿({content_length}å­—ç¬¦)ï¼Œå·²æˆªå–è‡³80000å­—ç¬¦")
                    else:
                        truncated_content = self.paper_content
                    
                    # åˆ›å»ºåˆ†ææç¤º
                    prompt = f"è¯·åŸºäºä»¥ä¸‹è®ºæ–‡å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{truncated_content}\n\né—®é¢˜ï¼š{question.question}"

                    # ä½¿ç”¨å•çº¿ç¨‹ç‰ˆæœ¬çš„è¯·æ±‚å‡½æ•°
                    response = None
                    for resp in request_gpt_model_in_new_thread_with_ui_alive(
                        inputs=prompt,
                        inputs_show_user=question.question,  # æ˜¾ç¤ºé—®é¢˜æœ¬èº«
                        llm_kwargs=self.llm_kwargs,
                        chatbot=self.chatbot,
                        history=[],  # ç©ºå†å²ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜ç‹¬ç«‹åˆ†æ
                        sys_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘ç ”è®ºæ–‡åˆ†æåŠ©æ‰‹ï¼Œéœ€è¦ä»”ç»†é˜…è¯»è®ºæ–‡å†…å®¹å¹¶å›ç­”é—®é¢˜ã€‚è¯·ä¿æŒå®¢è§‚ã€å‡†ç¡®ï¼Œå¹¶åŸºäºè®ºæ–‡å†…å®¹æä¾›æ·±å…¥åˆ†æã€‚"
                    ):
                        response = resp

                    if response:
                        self.results[question.id] = response
                        self.update_detailed_progress(paper_name, "analyzing", question_index, f"âœ… å®Œæˆ: {question.description}")
                        return True
                    else:
                        if retry_count < self.max_retries - 1:
                            self.update_detailed_progress(paper_name, "analyzing", question_index, 
                                                       f"âš ï¸ åˆ†æå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {question.description}")
                            continue
                        else:
                            self.update_detailed_progress(paper_name, "analyzing", question_index, f"âŒ æœ€ç»ˆå¤±è´¥: {question.description}")
                            return False

                except Exception as e:
                    error_msg = str(e)
                    if retry_count < self.max_retries - 1:
                        self.update_detailed_progress(paper_name, "analyzing", question_index, 
                                                   f"âš ï¸ åˆ†æå‡ºé”™ï¼Œå‡†å¤‡é‡è¯•: {question.description} - é”™è¯¯: {error_msg}")
                        continue
                    else:
                        self.update_detailed_progress(paper_name, "analyzing", question_index, 
                                                   f"âŒ æœ€ç»ˆé”™è¯¯: {question.description} - {error_msg}")
                        return False
            
            return False

    def _generate_summary(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆæ€»ç»“æŠ¥å‘Š - éç”Ÿæˆå™¨ç‰ˆæœ¬ï¼Œç”¨äºå¤šçº¿ç¨‹"""
        paper_name = os.path.basename(self.paper_file_path) if self.paper_file_path else "æœªçŸ¥è®ºæ–‡"
        
        # æ›´æ–°è¿›åº¦
        self.update_detailed_progress(paper_name, "summarizing", status="æ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘è¯·æ±‚
        with self.request_semaphore:
            for retry_count in range(self.max_retries):
                try:
                    # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚å†²çª
                    if retry_count > 0:
                        delay = self.retry_delay + random.uniform(1, 3)
                        time.sleep(delay)
                        self.update_detailed_progress(paper_name, "summarizing", 
                                                   status=f"é‡è¯•ç”Ÿæˆæ€»ç»“æŠ¥å‘Š ({retry_count + 1}/{self.max_retries})...")
                    
                    summary_prompt = "è¯·åŸºäºä»¥ä¸‹å¯¹è®ºæ–‡çš„å„ä¸ªæ–¹é¢çš„åˆ†æï¼Œç”Ÿæˆä¸€ä»½å…¨é¢çš„è®ºæ–‡è§£è¯»æŠ¥å‘Šã€‚æŠ¥å‘Šåº”è¯¥ç®€æ˜æ‰¼è¦åœ°å‘ˆç°è®ºæ–‡çš„å…³é”®å†…å®¹ï¼Œå¹¶ä¿æŒé€»è¾‘è¿è´¯æ€§ã€‚"

                    for q in self.questions:
                        if q.id in self.results:
                            summary_prompt += f"\n\nå…³äº{q.description}çš„åˆ†æ:\n{self.results[q.id]}"
                    
                    # æ£€æŸ¥æç¤ºé•¿åº¦ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
                    if len(summary_prompt) > 80000:
                        # æˆªå–æç¤ºå†…å®¹
                        summary_prompt = summary_prompt[:80000] + "\n\n[æç¤ºå†…å®¹å·²æˆªå–ï¼Œä¿ç•™æ ¸å¿ƒéƒ¨åˆ†]"
                        self.update_detailed_progress(paper_name, "summarizing", 
                                                   status="âš ï¸ æ€»ç»“æç¤ºè¿‡é•¿ï¼Œå·²æˆªå–è‡³80000å­—ç¬¦")

                    # ä½¿ç”¨å•çº¿ç¨‹ç‰ˆæœ¬çš„è¯·æ±‚å‡½æ•°
                    response = None
                    for resp in request_gpt_model_in_new_thread_with_ui_alive(
                        inputs=summary_prompt,
                        inputs_show_user="ç”Ÿæˆè®ºæ–‡è§£è¯»æŠ¥å‘Š",
                        llm_kwargs=self.llm_kwargs,
                        chatbot=self.chatbot,
                        history=[],
                        sys_prompt="ä½ æ˜¯ä¸€ä¸ªç§‘ç ”è®ºæ–‡è§£è¯»ä¸“å®¶ï¼Œè¯·å°†å¤šä¸ªæ–¹é¢çš„åˆ†ææ•´åˆä¸ºä¸€ä»½å®Œæ•´ã€è¿è´¯ã€æœ‰æ¡ç†çš„æŠ¥å‘Šã€‚æŠ¥å‘Šåº”å½“é‡ç‚¹çªå‡ºï¼Œå±‚æ¬¡åˆ†æ˜ï¼Œå¹¶ä¸”ä¿æŒå­¦æœ¯æ€§å’Œå®¢è§‚æ€§ã€‚"
                    ):
                        response = resp

                    if response:
                        self.update_detailed_progress(paper_name, "summarizing", status="âœ… æ€»ç»“æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                        return response
                    else:
                        if retry_count < self.max_retries - 1:
                            self.update_detailed_progress(paper_name, "summarizing", 
                                                       status="âš ï¸ æ€»ç»“æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•")
                            continue
                        else:
                            self.update_detailed_progress(paper_name, "summarizing", status="âŒ æ€»ç»“æŠ¥å‘Šç”Ÿæˆæœ€ç»ˆå¤±è´¥")
                            return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"

                except Exception as e:
                    error_msg = str(e)
                    if retry_count < self.max_retries - 1:
                        self.update_detailed_progress(paper_name, "summarizing", 
                                                   status=f"âš ï¸ æ€»ç»“æŠ¥å‘Šç”Ÿæˆå‡ºé”™ï¼Œå‡†å¤‡é‡è¯• - é”™è¯¯: {error_msg}")
                        continue
                    else:
                        self.update_detailed_progress(paper_name, "summarizing", 
                                                   status=f"âŒ æ€»ç»“æŠ¥å‘Šç”Ÿæˆæœ€ç»ˆé”™è¯¯: {error_msg}")
                        return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥: " + str(e)
            
            return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥: é‡è¯•æ¬¡æ•°å·²ç”¨å®Œ"

    def save_report(self, report: str, paper_file_path: str = None) -> str:
        """ä¿å­˜åˆ†ææŠ¥å‘Šï¼Œè¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„"""
        paper_name = os.path.basename(paper_file_path) if paper_file_path else "æœªçŸ¥è®ºæ–‡"
        
        # æ›´æ–°è¿›åº¦
        self.update_detailed_progress(paper_name, "saving", status="æ­£åœ¨ä¿å­˜åˆ†ææŠ¥å‘Š...")
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # è·å–PDFæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        pdf_filename = "æœªçŸ¥è®ºæ–‡"
        if paper_file_path and os.path.exists(paper_file_path):
            pdf_filename = os.path.splitext(os.path.basename(paper_file_path))[0]
            # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡å’Œä¸‹åˆ’çº¿
            import re
            pdf_filename = re.sub(r'[^\w\u4e00-\u9fff]', '_', pdf_filename)
            # å¦‚æœæ–‡ä»¶åè¿‡é•¿ï¼Œæˆªå–å‰50ä¸ªå­—ç¬¦
            if len(pdf_filename) > 50:
                pdf_filename = pdf_filename[:50]

        # ä¿å­˜ä¸ºMarkdownæ–‡ä»¶
        try:
            md_content = f"# è®ºæ–‡å¿«é€Ÿè§£è¯»æŠ¥å‘Š\n\n{report}"
            for q in self.questions:
                if q.id in self.results:
                    md_content += f"\n\n## {q.description}\n\n{self.results[q.id]}"

            result_file = write_history_to_file(
                history=[md_content],
                file_basename=f"{timestamp}_{pdf_filename}_è§£è¯»æŠ¥å‘Š.md"
            )

            if result_file and os.path.exists(result_file):
                promote_file_to_downloadzone(result_file, chatbot=self.chatbot)
                self.update_detailed_progress(paper_name, "saving", status=f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {os.path.basename(result_file)}")
                return result_file
            else:
                self.update_detailed_progress(paper_name, "saving", status="âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥")
                return None
        except Exception as e:
            self.update_detailed_progress(paper_name, "saving", status=f"âŒ ä¿å­˜é”™è¯¯: {str(e)}")
            return None

    def analyze_single_paper(self, paper_path: str) -> Tuple[str, str]:
        """åˆ†æå•ç¯‡è®ºæ–‡ - è¿”å›(è®ºæ–‡å, æŠ¥å‘Šæ–‡ä»¶è·¯å¾„)"""
        try:
            # é‡ç½®åˆ†æå™¨çŠ¶æ€
            self.paper_content = ""
            self.results = {}
            self.paper_file_path = None
            self.current_question_index = 0
            
            paper_name = os.path.basename(paper_path)
            
            # åŠ è½½è®ºæ–‡
            if not self._load_paper(paper_path):
                return paper_name, None

            # åˆ†æå…³é”®é—®é¢˜
            for i, question in enumerate(self.questions):
                self._analyze_question(question, i)

            # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            final_report = self._generate_summary()

            # ä¿å­˜æŠ¥å‘Š
            saved_file = self.save_report(final_report, self.paper_file_path)
            
            return paper_name, saved_file
            
        except Exception as e:
            paper_name = os.path.basename(paper_path)
            self.update_detailed_progress(paper_name, "error", status=f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            return paper_name, None

    def analyze_papers_parallel(self, paper_files: List[str], max_workers: int = 3) -> List[Tuple[str, str]]:
        """å¹¶è¡Œåˆ†æå¤šç¯‡è®ºæ–‡"""
        self.total_papers = len(paper_files)
        self.current_progress = 0
        
        results = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_paper = {
                executor.submit(self.analyze_single_paper, paper_file): paper_file 
                for paper_file in paper_files
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_paper):
                paper_file = future_to_paper[future]
                try:
                    paper_name, report_path = future.result()
                    if report_path:
                        results.append((paper_name, report_path))
                        self.update_paper_progress(paper_name, "âœ… å®Œæˆ")
                    else:
                        self.update_paper_progress(paper_name, "âŒ å¤±è´¥")
                except Exception as e:
                    paper_name = os.path.basename(paper_file)
                    self.update_paper_progress(paper_name, f"âŒ é”™è¯¯: {str(e)}")
        
        return results


def _find_paper_files(path: str) -> List[str]:
    """æŸ¥æ‰¾è·¯å¾„ä¸­çš„æ‰€æœ‰è®ºæ–‡æ–‡ä»¶"""
    paper_files = []
    
    if os.path.isfile(path):
        # å¦‚æœæ˜¯å•ä¸ªæ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ ¼å¼
        file_ext = os.path.splitext(path)[1].lower()
        if file_ext in ['.pdf', '.docx', '.doc', '.txt', '.md', '.tex']:
            paper_files.append(path)
        return paper_files

    # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’æœç´¢æ‰€æœ‰æ”¯æŒçš„è®ºæ–‡æ–‡ä»¶
    if os.path.isdir(path):
        supported_extensions = ['.pdf', '.docx', '.doc', '.txt', '.md', '.tex']
        
        for root, dirs, files in os.walk(path):
            for file in files:
                file_path = os.path.join(root, file)
                file_ext = os.path.splitext(file)[1].lower()
                if file_ext in supported_extensions:
                    paper_files.append(file_path)
    
    return paper_files


def download_paper_by_id(paper_info, chatbot, history) -> str:
    """ä¸‹è½½è®ºæ–‡å¹¶è¿”å›ä¿å­˜è·¯å¾„"""
    from crazy_functions.review_fns.data_sources.scihub_source import SciHub
    id_type, paper_id = paper_info

    # åˆ›å»ºä¿å­˜ç›®å½• - ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€æ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    user_name = chatbot.get_user() if hasattr(chatbot, 'get_user') else "default"
    from toolbox import get_log_folder, get_user
    base_save_dir = get_log_folder(get_user(chatbot), plugin_name='paper_download')
    save_dir = os.path.join(base_save_dir, f"papers_{timestamp}")
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    save_path = Path(save_dir)

    chatbot.append([f"ä¸‹è½½è®ºæ–‡", f"æ­£åœ¨ä¸‹è½½{'arXiv' if id_type == 'arxiv' else 'DOI'} {paper_id} çš„è®ºæ–‡..."])
    update_ui(chatbot=chatbot, history=history)

    pdf_path = None

    try:
        if id_type == 'arxiv':
            # ä½¿ç”¨æ”¹è¿›çš„arxivæŸ¥è¯¢æ–¹æ³•
            formatted_id = format_arxiv_id(paper_id)
            paper_result = get_arxiv_paper(formatted_id)

            if not paper_result:
                chatbot.append([f"ä¸‹è½½å¤±è´¥", f"æœªæ‰¾åˆ°arXivè®ºæ–‡: {paper_id}"])
                update_ui(chatbot=chatbot, history=history)
                return None

            # ä¸‹è½½PDF
            filename = f"arxiv_{paper_id.replace('/', '_')}.pdf"
            pdf_path = str(save_path / filename)
            paper_result.download_pdf(filename=pdf_path)

        else:  # doi
            # ä¸‹è½½DOI
            sci_hub = SciHub(
                doi=paper_id,
                path=save_path
            )
            pdf_path = sci_hub.fetch()

        # æ£€æŸ¥ä¸‹è½½ç»“æœ
        if pdf_path and os.path.exists(pdf_path):
            promote_file_to_downloadzone(pdf_path, chatbot=chatbot)
            chatbot.append([f"ä¸‹è½½æˆåŠŸ", f"å·²æˆåŠŸä¸‹è½½è®ºæ–‡: {os.path.basename(pdf_path)}"])
            update_ui(chatbot=chatbot, history=history)
            return pdf_path
        else:
            chatbot.append([f"ä¸‹è½½å¤±è´¥", f"è®ºæ–‡ä¸‹è½½å¤±è´¥: {paper_id}"])
            update_ui(chatbot=chatbot, history=history)
            return None

    except Exception as e:
        chatbot.append([f"ä¸‹è½½é”™è¯¯", f"ä¸‹è½½è®ºæ–‡æ—¶å‡ºé”™: {str(e)}"])
        update_ui(chatbot=chatbot, history=history)
        return None


@CatchException
def æ‰¹é‡è®ºæ–‡é€Ÿè¯»(txt: str, llm_kwargs: Dict, plugin_kwargs: Dict, chatbot: List,
             history: List, system_prompt: str, user_request: str):
    """ä¸»å‡½æ•° - æ‰¹é‡è®ºæ–‡é€Ÿè¯»ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
    # åˆå§‹åŒ–åˆ†æå™¨
    chatbot.append(["å‡½æ•°æ’ä»¶åŠŸèƒ½åŠä½¿ç”¨æ–¹å¼", "æ‰¹é‡è®ºæ–‡é€Ÿè¯»ï¼ˆå¤šçº¿ç¨‹ç‰ˆï¼‰ï¼šæ‰¹é‡åˆ†æå¤šä¸ªè®ºæ–‡æ–‡ä»¶ï¼Œä¸ºæ¯ç¯‡è®ºæ–‡ç”Ÿæˆç‹¬ç«‹çš„é€Ÿè¯»æŠ¥å‘Šï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ã€‚ <br><br>ğŸ“‹ ä½¿ç”¨æ–¹å¼ï¼š<br>1ã€è¾“å…¥åŒ…å«å¤šä¸ªPDFæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„<br>2ã€æˆ–è€…è¾“å…¥å¤šä¸ªè®ºæ–‡IDï¼ˆDOIæˆ–arXiv IDï¼‰ï¼Œç”¨é€—å·åˆ†éš”<br>3ã€ç‚¹å‡»æ’ä»¶å¼€å§‹æ‰¹é‡åˆ†æ"])
    yield from update_ui(chatbot=chatbot, history=history)

    paper_files = []

    # æ£€æŸ¥è¾“å…¥æ˜¯å¦åŒ…å«è®ºæ–‡IDï¼ˆå¤šä¸ªIDç”¨é€—å·åˆ†éš”ï¼‰
    if ',' in txt:
        # å¤„ç†å¤šä¸ªè®ºæ–‡ID
        paper_ids = [id.strip() for id in txt.split(',') if id.strip()]
        chatbot.append(["æ£€æµ‹åˆ°å¤šä¸ªè®ºæ–‡ID", f"æ£€æµ‹åˆ° {len(paper_ids)} ä¸ªè®ºæ–‡IDï¼Œå‡†å¤‡æ‰¹é‡ä¸‹è½½..."])
        yield from update_ui(chatbot=chatbot, history=history)

        for i, paper_id in enumerate(paper_ids):
            paper_info = extract_paper_id(paper_id)
            if paper_info:
                chatbot.append([f"ä¸‹è½½è®ºæ–‡ {i+1}/{len(paper_ids)}", f"æ­£åœ¨ä¸‹è½½ {'arXiv' if paper_info[0] == 'arxiv' else 'DOI'} ID: {paper_info[1]}..."])
                yield from update_ui(chatbot=chatbot, history=history)

                paper_file = download_paper_by_id(paper_info, chatbot, history)
                if paper_file:
                    paper_files.append(paper_file)
                else:
                    chatbot.append([f"ä¸‹è½½å¤±è´¥", f"æ— æ³•ä¸‹è½½è®ºæ–‡: {paper_id}"])
                    yield from update_ui(chatbot=chatbot, history=history)
            else:
                chatbot.append([f"IDæ ¼å¼é”™è¯¯", f"æ— æ³•è¯†åˆ«è®ºæ–‡IDæ ¼å¼: {paper_id}"])
                yield from update_ui(chatbot=chatbot, history=history)
    else:
        # æ£€æŸ¥å•ä¸ªè®ºæ–‡ID
        paper_info = extract_paper_id(txt)
        if paper_info:
            # å•ä¸ªè®ºæ–‡ID
            chatbot.append(["æ£€æµ‹åˆ°è®ºæ–‡ID", f"æ£€æµ‹åˆ°{'arXiv' if paper_info[0] == 'arxiv' else 'DOI'} ID: {paper_info[1]}ï¼Œå‡†å¤‡ä¸‹è½½è®ºæ–‡..."])
            yield from update_ui(chatbot=chatbot, history=history)

            paper_file = download_paper_by_id(paper_info, chatbot, history)
            if paper_file:
                paper_files.append(paper_file)
            else:
                report_exception(chatbot, history, a=f"ä¸‹è½½è®ºæ–‡å¤±è´¥", b=f"æ— æ³•ä¸‹è½½{'arXiv' if paper_info[0] == 'arxiv' else 'DOI'}è®ºæ–‡: {paper_info[1]}")
                yield from update_ui(chatbot=chatbot, history=history)
                return
        else:
            # æ£€æŸ¥è¾“å…¥è·¯å¾„
            if not os.path.exists(txt):
                report_exception(chatbot, history, a=f"æ‰¹é‡è§£æè®ºæ–‡: {txt}", b=f"æ‰¾ä¸åˆ°æ–‡ä»¶æˆ–æ— æƒè®¿é—®: {txt}")
                yield from update_ui(chatbot=chatbot, history=history)
                return

            # éªŒè¯è·¯å¾„å®‰å…¨æ€§
            user_name = chatbot.get_user()
            validate_path_safety(txt, user_name)

            # æŸ¥æ‰¾æ‰€æœ‰è®ºæ–‡æ–‡ä»¶
            paper_files = _find_paper_files(txt)

            if not paper_files:
                report_exception(chatbot, history, a=f"æ‰¹é‡è§£æè®ºæ–‡", b=f"åœ¨è·¯å¾„ {txt} ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„è®ºæ–‡æ–‡ä»¶")
                yield from update_ui(chatbot=chatbot, history=history)
                return

    yield from update_ui(chatbot=chatbot, history=history)

    # å¼€å§‹æ‰¹é‡åˆ†æ
    if not paper_files:
        chatbot.append(["é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯åˆ†æçš„è®ºæ–‡æ–‡ä»¶"])
        yield from update_ui(chatbot=chatbot, history=history)
        return

    # åˆ›å»ºæ‰¹é‡åˆ†æå™¨
    analyzer = BatchPaperAnalyzer(llm_kwargs, plugin_kwargs, chatbot, history, system_prompt)
    
    # æ˜¾ç¤ºåˆ†æé…ç½®ä¿¡æ¯
    total_questions = len(analyzer.questions)
    chatbot.append(["å¼€å§‹æ‰¹é‡åˆ†æ", f"æ‰¾åˆ° {len(paper_files)} ç¯‡è®ºæ–‡ï¼Œå¼€å§‹å¤šçº¿ç¨‹æ‰¹é‡åˆ†æ...\n\nğŸ“‹ åˆ†æé…ç½®ï¼š\n- æ¯ç¯‡è®ºæ–‡åˆ†æ {total_questions} ä¸ªé—®é¢˜\n- å¹¶è¡Œçº¿ç¨‹æ•°ï¼š{min(3, len(paper_files))}\n- é¢„è®¡æ€»åˆ†ææ­¥éª¤ï¼š{len(paper_files) * (total_questions + 3)} æ­¥\n\nğŸ”„ å¼€å§‹å¤„ç†..."])
    yield from update_ui(chatbot=chatbot, history=history)
    
    # è®¾ç½®çº¿ç¨‹æ•°ï¼ˆæ ¹æ®è®ºæ–‡æ•°é‡è°ƒæ•´ï¼‰
    max_workers = min(3, len(paper_files))  # æœ€å¤š3ä¸ªçº¿ç¨‹
    
    # æ˜¾ç¤ºè¯¦ç»†è¿›åº¦è¯´æ˜
    chatbot.append(["è¯¦ç»†è¿›åº¦è¯´æ˜", f"ğŸ“Š è¿›åº¦æ˜¾ç¤ºè¯´æ˜ï¼š\n\nğŸ”„ å¤„ç†é˜¶æ®µï¼š\n- loading: åŠ è½½è®ºæ–‡å†…å®¹\n- analyzing: åˆ†æé—®é¢˜ (1-{total_questions})\n- summarizing: ç”Ÿæˆæ€»ç»“æŠ¥å‘Š\n- saving: ä¿å­˜åˆ†ææŠ¥å‘Š\n\nğŸ“ˆ è¿›åº¦ä¿¡æ¯ï¼š\n- å½“å‰è®ºæ–‡åç§°\n- å½“å‰å¤„ç†é˜¶æ®µ\n- å½“å‰é—®é¢˜è¿›åº¦ (å¦‚é€‚ç”¨)\n- å¤„ç†çŠ¶æ€"])
    yield from update_ui(chatbot=chatbot, history=history)
    
    # å¹¶è¡Œåˆ†æè®ºæ–‡
    successful_reports = analyzer.analyze_papers_parallel(paper_files, max_workers)
    
    # æ›´æ–°æœ€ç»ˆè¿›åº¦
    yield from update_ui(chatbot=chatbot, history=history)

    # ç”Ÿæˆæ‰¹é‡åˆ†ææ€»ç»“
    failed_count = len(paper_files) - len(successful_reports)
    summary = f"ğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼\n\n"
    summary += f"ğŸ“Š åˆ†æç»Ÿè®¡ï¼š\n"
    summary += f"- æ€»è®ºæ–‡æ•°ï¼š{len(paper_files)}\n"
    summary += f"- æˆåŠŸåˆ†æï¼š{len(successful_reports)}\n"
    summary += f"- åˆ†æå¤±è´¥ï¼š{failed_count}\n"
    summary += f"- å¹¶è¡Œçº¿ç¨‹ï¼š{max_workers}\n"
    summary += f"- æ¯ç¯‡è®ºæ–‡åˆ†æé—®é¢˜ï¼š{total_questions} ä¸ª\n\n"
    
    if successful_reports:
        summary += f"âœ… æˆåŠŸç”ŸæˆæŠ¥å‘Šï¼š\n"
        for paper_name, report_path in successful_reports:
            summary += f"- {paper_name} â†’ {os.path.basename(report_path)}\n"
    
    if failed_count > 0:
        summary += f"\nâŒ åˆ†æå¤±è´¥çš„è®ºæ–‡ï¼š{failed_count} ç¯‡"
    
    summary += f"\n\nğŸ’¡ æç¤ºï¼šæ‰€æœ‰æŠ¥å‘Šå·²ä¿å­˜åˆ°ä¸‹è½½åŒºåŸŸï¼Œå¯ç›´æ¥ä¸‹è½½ä½¿ç”¨ã€‚"

    chatbot.append(["æ‰¹é‡åˆ†æå®Œæˆ", summary])
    yield from update_ui(chatbot=chatbot, history=history) 